{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is this repo about?\n",
    "\n",
    "This repo compiles my notes and code snippets from the algorithms course that I took from Augusto Galego.\n",
    "\n",
    "# Big O Notation\n",
    "\n",
    "## What is Big O Notation?\n",
    "\n",
    "It's all about scalability, not necessarily speed. It's about how much time it takes to run an algorithm grows as the input size grows.\n",
    "\n",
    "## Let's break it down\n",
    "\n",
    "[^1]\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  A[8]-->B[7]\n",
    "  B-->C[6]\n",
    "  C-->D[5]\n",
    "  D-->E[4]\n",
    "  E-->F[3]\n",
    "  F-->G[2]\n",
    "  G-->H[1]\n",
    "  H-->I[0]\n",
    "```\n",
    "\n",
    "### Temporal Complexity\n",
    "\n",
    "\n",
    "Temporal complexity is about how much time an algorithm takes to run as the input size grows. Maybe how many `if` statements are in the algorithm, how many times the algorithm loops, etc.\n",
    "\n",
    "Imagine that we want to find the number `4` in the graph [^1]. We would have to go through each node to find it. If we were to add more nodes to the graph, we would have to go through each node to find the number `4`. This is a linear search. So we can give it a temporal complexity of O(n), where `n` is the number of nodes in the graph.\n",
    "\n",
    "### Spatial Complexity\n",
    "\n",
    "Spatial complexity is about how much memory an algorithm uses as the input size grows. Maybe how many variables are in the algorithm, how many arrays, etc.\n",
    "\n",
    "Now imagine that we want to find the number `4` in the graph [^1]. We would only have to allocate 1 variable for each node being visited. If we were to add more nodes to the graph, we would only have to allocate 1 variable for each node being visited. This is a linear search. So we can give it a spatial complexity of O(1), where `1` means that the algorithm does not allocate more memory as the input size grows.\n",
    "\n",
    "[^1]: This is a graph of a simple algorithm that goes through each node to find the number `4`.\n",
    "\n",
    "## Common Big O Notations\n",
    "\n",
    "### O(1) - Constant Time\n",
    "\n",
    "The algorithm does not change its time or space complexity as the input size grows. An example for this is an algorithm that returns the first element of an array. Note that if for some reason, we have an algorithm that searches the top 15 elements in an array, it would still be O(1) because the algorithm does not change its space complexity as the input size grows. Big O is about scalability, not speed nor memory usage.\n",
    "\n",
    "### O(log n) - Logarithmic Time\n",
    "\n",
    "The logarithmic scale can be hard for some people to understand, but following the list below, it should be easier to understand:\n",
    "\n",
    "- Log2(10) -> 3.32\n",
    "- Log2(20) -> 4.32\n",
    "- Log2(30) -> 4.90\n",
    "- Log2(40) -> 5.32\n",
    "\n",
    "You can se that even though we are increasing the input size by 10, the time it takes to run the algorithm does not increase by 10. It increases by a smaller number. This is the power of logarithmic time. You can watch [this video](https://www.youtube.com/watch?v=cEvgcoyZvB4) from 3Blue1Brown to understand logarithms better.\n",
    "\n",
    "In an O `(log n)` algorithm, the time it takes to run the algorithm grows \"almost\" linearly even though the input size grows exponentially. An example of this is a binary search.\n",
    "\n",
    "#### Binary Search\n",
    "\n",
    "This is a common algorithm that has a time complexity of O(log n). In this algorithm we search a given element looking first for an element in the middle of an array (the array must be sorted). In the graph [^1] assuming we are trying to find number `4`, we would first look for the number `5`, then we would split in half and look for the number `4`, and so on. This is a logarithmic search. Even in an array of 1000 elements, we would only have to look for 10 elements to find the number `4`.\n",
    "\n",
    "### O(n) - Linear Time\n",
    "\n",
    "In an O(n) algorithm, the time it takes to run the algorithm grows linearly as the input size grows. An example of this is a linear search as we saw in the graph [^1] first example in [Temporal Complexity](#temporal-complexity). We usually take an pessimistic approach when analyzing algorithms. So if we have an algorithm that goes through each element in an array, we can say that it has a time complexity of O(n).\n",
    "\n",
    "For a space complexity, we can say that an algorithm that allocates a variable for each element in an array has a space complexity of O(n). An example can be an algorithm that duplicates an array by allocating each element in a new array than multiplying it by 2.\n",
    "\n",
    "### O(n log n) - Linearithmic Time \n",
    "\n",
    "An example of this is the quicksort algorithm. In this algorithm, we first choose a pivot element, then we split the array in two, one with elements smaller than the pivot and the other with elements bigger than the pivot. We then repeat the process for each half. This is a linearithmic time algorithm. Basically divide and conquer.\n",
    "\n",
    "The math behind this is that we have a O(n) operation that is repeated recursively O(log n) times. So we have O(n log n).\n",
    "\n",
    "### O(n^2) - Quadratic Time\n",
    "\n",
    "An example of this is a bubble sort algorithm. In this algorithm, we compare each element with the next element and swap them if the next element is smaller. We repeat this process for each element in the array. This is a quadratic time algorithm. The time it takes to run the algorithm grows quadratically as the input size grows.\n",
    "\n",
    "You can easily spot this in code when you have something like:\n",
    "\n",
    "```python\n",
    "for i in range(len(array)):\n",
    "  for j in range(len(array)):\n",
    "    # do something\n",
    "```\n",
    "\n",
    "### Extras\n",
    "\n",
    "#### O(2^n) - Exponential Time\n",
    "\n",
    "An example of this is the fibonacci sequence. In this algorithm, we calculate the fibonacci sequence by adding the two previous numbers. This is an exponential time algorithm. The time it takes to run the algorithm grows exponentially as the input size grows.\n",
    "\n",
    "#### O(n!) - Factorial Time\n",
    "\n",
    "An example of this is the traveling salesman problem. In this algorithm, we have to find the shortest path that visits each city exactly once and returns to the origin city. This is a factorial time algorithm. The time it takes to run the algorithm grows factorial as the input size grows.\n",
    "\n",
    "#### O(sqrt(n)) - Square Root Time\n",
    "\n",
    "An example of this is the primality test. In this algorithm, we check if a number is prime by checking if it is divisible by any number from 2 to the square root of the number. This is a square root time algorithm. The time it takes to run the algorithm grows as the squ\n",
    "are root of the input size grows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
